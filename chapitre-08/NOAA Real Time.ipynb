{"cells":[{"cell_type":"markdown","source":["### Data & Innovation Day - Realtime - Azure AI Services and Fabric demonstration\n","\n","The NOAA’s Center for Operational Oceanographic Products and Services (CO-OPS) provides real-time information on tides, water levels, currents, and other coastal oceanographic and meteorological data. This data serves a crucial purpose in aiding the maritime transportation industry by ensuring safe and efficient navigation through waterways and ports. In addition, current trends and predictions play a significant role in assisting individuals in preparing for potential flooding due to storms, tsunamis, and sea level fluctuations.\n","\n","![A blue and black rectangle with a white cross  Description automatically generated](https://dataplatformblogcdn.azureedge.net/wp-content/uploads/2023/07/a-blue-and-black-rectangle-with-a-white-cross-des.png)\n","\n","https://blog.fabric.microsoft.com/en-US/blog/microsoft-fabric-event-streams-generating-real-time-insights-with-python-kql-and-powerbi/\n","\n","https://tidesandcurrents.noaa.gov/map/index.html\n"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"e3a836b5-7390-4af4-a844-fecfee2e252c"},{"cell_type":"code","source":["# Welcome to your new notebook\n","# Type here in the cell editor to add code!\n","%pip install azure-eventhub\n","%pip install azure-identity\n","%pip install aiohttp"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"47381787-0f0a-4cf7-9b67-91de01da9d20","statement_id":10,"statement_ids":[3,4,5,6,7,8,9,10],"state":"finished","livy_statement_state":"available","queued_time":"2024-04-29T13:00:41.7591252Z","session_start_time":null,"execution_start_time":"2024-04-29T13:00:46.4435932Z","execution_finish_time":"2024-04-29T13:01:15.124973Z","parent_msg_id":"f1489ad6-219b-458a-87e6-153f2365dab9"},"text/plain":"StatementMeta(, 47381787-0f0a-4cf7-9b67-91de01da9d20, 10, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Collecting azure-eventhub\n  Downloading azure_eventhub-5.11.7-py3-none-any.whl (320 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.6/320.6 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: azure-core>=1.14.0 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from azure-eventhub) (1.29.4)\nRequirement already satisfied: typing-extensions>=4.0.1 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from azure-eventhub) (4.5.0)\nRequirement already satisfied: requests>=2.18.4 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from azure-core>=1.14.0->azure-eventhub) (2.31.0)\nRequirement already satisfied: six>=1.11.0 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from azure-core>=1.14.0->azure-eventhub) (1.16.0)\nCollecting typing-extensions>=4.0.1 (from azure-eventhub)\n  Downloading typing_extensions-4.11.0-py3-none-any.whl (34 kB)\nRequirement already satisfied: charset-normalizer<4,>=2 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from requests>=2.18.4->azure-core>=1.14.0->azure-eventhub) (3.3.1)\nRequirement already satisfied: idna<4,>=2.5 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from requests>=2.18.4->azure-core>=1.14.0->azure-eventhub) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from requests>=2.18.4->azure-core>=1.14.0->azure-eventhub) (1.26.17)\nRequirement already satisfied: certifi>=2017.4.17 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from requests>=2.18.4->azure-core>=1.14.0->azure-eventhub) (2023.7.22)\nInstalling collected packages: typing-extensions, azure-eventhub\n  Attempting uninstall: typing-extensions\n    Found existing installation: typing_extensions 4.5.0\n    Not uninstalling typing-extensions at /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages, outside environment /nfs4/pyenv-564f305f-022b-43f9-b514-091f2ef21ae4\n    Can't uninstall 'typing_extensions'. No files were found to uninstall.\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nsentence-transformers 2.0.0 requires sentencepiece, which is not installed.\nsentence-transformers 2.0.0 requires torchvision, which is not installed.\ndash 2.14.0 requires Flask<2.3.0,>=1.0.4, but you have flask 3.0.0 which is incompatible.\ndash 2.14.0 requires Werkzeug<2.3.0, but you have werkzeug 3.0.1 which is incompatible.\ntensorflow 2.12.1 requires typing-extensions<4.6.0,>=3.6.6, but you have typing-extensions 4.11.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed azure-eventhub-5.11.7 typing-extensions-4.11.0\n\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\nNote: you may need to restart the kernel to use updated packages.\nRequirement already satisfied: azure-identity in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (1.14.1)\nRequirement already satisfied: azure-core<2.0.0,>=1.11.0 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from azure-identity) (1.29.4)\nRequirement already satisfied: cryptography>=2.5 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from azure-identity) (41.0.5)\nRequirement already satisfied: msal<2.0.0,>=1.20.0 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from azure-identity) (1.24.1)\nRequirement already satisfied: msal-extensions<2.0.0,>=0.3.0 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from azure-identity) (1.0.0)\nRequirement already satisfied: requests>=2.18.4 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from azure-core<2.0.0,>=1.11.0->azure-identity) (2.31.0)\nRequirement already satisfied: six>=1.11.0 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from azure-core<2.0.0,>=1.11.0->azure-identity) (1.16.0)\nRequirement already satisfied: typing-extensions>=4.6.0 in /nfs4/pyenv-564f305f-022b-43f9-b514-091f2ef21ae4/lib/python3.10/site-packages (from azure-core<2.0.0,>=1.11.0->azure-identity) (4.11.0)\nRequirement already satisfied: cffi>=1.12 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from cryptography>=2.5->azure-identity) (1.16.0)\nRequirement already satisfied: PyJWT[crypto]<3,>=1.0.0 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from msal<2.0.0,>=1.20.0->azure-identity) (2.8.0)\nRequirement already satisfied: portalocker<3,>=1.0 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from msal-extensions<2.0.0,>=0.3.0->azure-identity) (2.8.2)\nRequirement already satisfied: pycparser in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=2.5->azure-identity) (2.21)\nRequirement already satisfied: charset-normalizer<4,>=2 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.11.0->azure-identity) (3.3.1)\nRequirement already satisfied: idna<4,>=2.5 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.11.0->azure-identity) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.11.0->azure-identity) (1.26.17)\nRequirement already satisfied: certifi>=2017.4.17 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.11.0->azure-identity) (2023.7.22)\n\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\nNote: you may need to restart the kernel to use updated packages.\nRequirement already satisfied: aiohttp in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (3.8.6)\nRequirement already satisfied: attrs>=17.3.0 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from aiohttp) (23.1.0)\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from aiohttp) (3.3.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from aiohttp) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from aiohttp) (4.0.3)\nRequirement already satisfied: yarl<2.0,>=1.0 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from aiohttp) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from aiohttp) (1.4.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from aiohttp) (1.3.1)\nRequirement already satisfied: idna>=2.0 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from yarl<2.0,>=1.0->aiohttp) (3.4)\n\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\nNote: you may need to restart the kernel to use updated packages.\nWarning: PySpark kernel has been restarted to use updated packages.\n\n"]}],"execution_count":1,"metadata":{"jupyter":{"outputs_hidden":true},"microsoft":{"language_group":"synapse_pyspark"}},"id":"49e672e1-85c4-4fa7-a07c-b0009a56eea2"},{"cell_type":"markdown","source":["**Collecting Coastal Water Level and Atmospheric Data with Python**\n","\n","NOAA provides real-time water level information that is updated every 6 minutes. You can use HTTP Get API call to fetch water level and location information for a specific station. This API takes a StationID (full list is here) as a required input and some other optional parameters. \n","\n","```xml\n","<data>\n","<metadata id=\"8594900\" name=\"Washington\" lat=\"38.8733\" lon=\"-77.0217\"/>\n","<observations>\n","<wl t=\"2023-07-09 19:30\" v=\"8.232\" s=\"0.023\" f=\"1,0,0,0\" q=\"p\"/>\n","</observations>\n","</data>\n","```"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"371b818a-1641-427d-b687-9654a2d686d4"},{"cell_type":"markdown","source":["**Create a request payload, issue the HTTP call and retrieve the response from NOAA into a Python function**"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"a01beed6-086a-4db8-bc71-508fb1a5513a"},{"cell_type":"code","source":["import requests\n","import time\n","from datetime import datetime\n","# Fetch water level data from tidesandcurrents.noaa.gov\n","def fetch_water_level(station_id):\n","    url = \"https://api.tidesandcurrents.noaa.gov/api/prod/datagetter\"\n","    # Collect water level for one station\n","    payload = {\n","        \"product\": \"water_level\",\n","        \"application\": \"Fabric EventStream\",  # Replace with your application name\n","        \"datum\": \"STND\",\n","        \"station\": station_id,  # Set station ID\n","        \"time_zone\": \"gmt\",\n","        \"units\": \"english\",  # Use \"english\" for feet, \"metric\" for meters\n","        \"format\": \"json\",\n","        \"date\": \"latest\",\n","    }\n","    response = requests.get(url, params=payload)\n","    if response.status_code == 200:\n","        data = response.json()\n","        return data\n","    return None"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"47381787-0f0a-4cf7-9b67-91de01da9d20","statement_id":22,"statement_ids":[22],"state":"finished","livy_statement_state":"available","queued_time":"2024-04-29T13:06:12.3260552Z","session_start_time":null,"execution_start_time":"2024-04-29T13:06:12.7980953Z","execution_finish_time":"2024-04-29T13:06:13.086334Z","parent_msg_id":"9eefe38e-4f52-48de-94e9-82e05d77b638"},"text/plain":"StatementMeta(, 47381787-0f0a-4cf7-9b67-91de01da9d20, 22, Finished, Available)"},"metadata":{}}],"execution_count":12,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language_group":"synapse_pyspark"}},"id":"11b4608b-69de-438d-b357-efed1a7d1225"},{"cell_type":"markdown","source":["**Unit test of API Call**\n","\n","```javascript\n","{'Current_time': '2024-01-12 08:20:25', 'Water Level Value': '8.937', 'Station Latitude': '47.5617', 'Station Longitude': '-122.6230', 'Station': 'Water Station'}\n","```"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"b8a08f32-edb4-4bb6-9c17-6135cbc56923"},{"cell_type":"code","source":["stationID = \"9445958\"  # Sample Bremerton, WA [9445958]\n","station_data = fetch_water_level(stationID)\n","\n","if station_data is not None:\n","                # Fetch station location\n","                data = station_data[\"data\"]\n","                if len(data) > 0:\n","                    water_level = data[0][\"v\"]\n","                station_latitude = station_data[\"metadata\"][\"lat\"]\n","                station_longitude = station_data[\"metadata\"][\"lon\"]\n","                # Create a data point with the time and value\n","                current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n","                # Generate the data structure\n","                water_point = {\n","                    \"Current_time\": current_time,\n","                    \"Water Level Value\": water_level,\n","                    \"Station Latitude\": station_latitude,\n","                    \"Station Longitude\": station_longitude,\n","                    \"Station\": \"Water Station\",\n","                }\n","print(water_point)\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"47381787-0f0a-4cf7-9b67-91de01da9d20","statement_id":23,"statement_ids":[23],"state":"finished","livy_statement_state":"available","queued_time":"2024-04-29T13:06:15.6232642Z","session_start_time":null,"execution_start_time":"2024-04-29T13:06:16.1204504Z","execution_finish_time":"2024-04-29T13:06:16.9820617Z","parent_msg_id":"087bd05b-d20e-4f92-98db-12d400e51c8f"},"text/plain":"StatementMeta(, 47381787-0f0a-4cf7-9b67-91de01da9d20, 23, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["{'Current_time': '2024-04-29 13:06:16', 'Water Level Value': '20.404', 'Station Latitude': '47.5617', 'Station Longitude': '-122.6230', 'Station': 'Water Station'}\n"]}],"execution_count":13,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language_group":"synapse_pyspark"}},"id":"021809a7-1926-46f5-bba6-8bfb88e31bdd"},{"cell_type":"markdown","source":["**Ingesting Data into Fabric Eventstreams (using Python)**\n","\n","Now that we have a well-tested Python code to retrieve all the data we need from its source, let us see how we can package the same in a ‘EventData’ structure and send it on to a Fabric Eventstream. For now, we will focus on the Python code but in a subsequent, we will show how to connect the Python code to a Eventstream.\n","\n","The above Python code acts as a Eventstream Producer/client and publishes water level data from NOAA every **6 minutes** to it. This is the interval at which NOAA refreshes its data. Refreshing at a higher frequency would be redundant."],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"549ae83c-f48b-4137-a4a0-ee2b7706a820"},{"cell_type":"code","source":["# code for fabric event stream\n","EVENTSTREAM_CONNECTION_STR = \"Endpoint=sb://esehamab2m01n7sux0kro6.servicebus.windows.net/;SharedAccessKeyName=key_c916bcd4-4274-938c-7928-9128f37bd34c;SharedAccessKey=sWPaynJsz3h4uP+D7zbLs88d5lTC+fxqG+AEhBaB2+A=;EntityPath=es_389f5a3e-d2d9-4936-9ab9-7a0629879502\"\n","EVENTSTREAM_NAME = \"es_389f5a3e-d2d9-4936-9ab9-7a0629879502\""],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"47381787-0f0a-4cf7-9b67-91de01da9d20","statement_id":24,"statement_ids":[24],"state":"finished","livy_statement_state":"available","queued_time":"2024-04-29T13:07:52.016708Z","session_start_time":null,"execution_start_time":"2024-04-29T13:07:52.5480546Z","execution_finish_time":"2024-04-29T13:07:52.7981686Z","parent_msg_id":"d48d1c2b-e555-496e-ad44-329768a72407"},"text/plain":"StatementMeta(, 47381787-0f0a-4cf7-9b67-91de01da9d20, 24, Finished, Available)"},"metadata":{}}],"execution_count":14,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language_group":"synapse_pyspark"}},"id":"66f1b8ca-f8e0-44c6-9171-8309f3ba32a5"},{"cell_type":"code","source":["import time\n","import json\n","from datetime import datetime\n","from azure.eventhub import EventData\n","from azure.eventhub.aio import EventHubProducerClient\n","\n","async def run():\n","    \"\"\"\n","    This function sends water level data to an EventStream using Azure Event Hubs.\n","    It fetches the current water level from a specified station and sends it as a JSON payload to the EventStream.\n","    The function runs indefinitely, generating a new data point every 6 minutes.\n","    \"\"\"\n","\n","    # Create a producer client to send messages to the EventStream.\n","    # Specify a connection string to your EventStream namespace and the eventstream name.\n","    producer = EventHubProducerClient.from_connection_string(\n","        conn_str=EVENTSTREAM_CONNECTION_STR, eventhub_name=EVENTSTREAM_NAME\n","    )\n","\n","    # Specify the station ID\n","    stationID = \"9445958\"  # Sample Bremerton, WA [9445958]\n","\n","    async with producer:\n","        while True:\n","            # Create a batch.\n","            event_data_batch = await producer.create_batch()\n","\n","            # Fetch current water level in feet\n","            station_data = fetch_water_level(stationID)\n","           \n","            if station_data is not None:\n","                # Fetch station location\n","                data = station_data[\"data\"]\n","                if len(data) > 0:\n","                    water_level = data[0][\"v\"]\n","                station_latitude = station_data[\"metadata\"][\"lat\"]\n","                station_longitude = station_data[\"metadata\"][\"lon\"]\n","\n","                # Create a data point with the time and value\n","                current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n","\n","                # Generate the data structure\n","                water_point = {\n","                    \"Current_time\": current_time,\n","                    \"Water Level Value\": water_level,\n","                    \"Station Latitude\": station_latitude,\n","                    \"Station Longitude\": station_longitude,\n","                    \"Station\": \"Water Station\",\n","                }\n","\n","                # Convert the curve data to JSON format\n","                json_water_data = json.dumps(water_point)\n","                event_data_batch.add(EventData(json_water_data))\n","\n","                # Send the batch of events to the event hub.\n","                await producer.send_batch(event_data_batch)\n","\n","            # Wait for 6 minutes before generating the next point\n","            time.sleep(360)\n","\n","await run()"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"47381787-0f0a-4cf7-9b67-91de01da9d20","statement_id":25,"statement_ids":[25],"state":"submitted","livy_statement_state":"running","queued_time":"2024-04-29T13:07:55.765902Z","session_start_time":null,"execution_start_time":"2024-04-29T13:07:56.2178598Z","execution_finish_time":null,"parent_msg_id":"18854fad-31c0-4ff7-a9b8-f102d9427214"},"text/plain":"StatementMeta(, 47381787-0f0a-4cf7-9b67-91de01da9d20, 25, Submitted, Running)"},"metadata":{}}],"execution_count":15,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language_group":"synapse_pyspark"}},"id":"1839d2f2-9180-4c0c-b4cf-19dc612ea655"}],"metadata":{"language_info":{"name":"python"},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"microsoft":{"language":"python","ms_spell_check":{"ms_spell_check_language":"en"},"language_group":"synapse_pyspark"},"widgets":{},"kernel_info":{"name":"synapse_pyspark"},"nteract":{"version":"nteract-front-end@1.0.0"},"notebook_environment":{},"synapse_widget":{"version":"0.1","state":{}},"save_output":true,"spark_compute":{"compute_id":"/trident/default","session_options":{"enableDebugMode":false,"conf":{}}},"dependencies":{"lakehouse":{"default_lakehouse":"92aacb52-edda-4317-b36e-46667dd9aa29","known_lakehouses":[{"id":"92aacb52-edda-4317-b36e-46667dd9aa29"}],"default_lakehouse_name":"FGILakeDB","default_lakehouse_workspace_id":"babe6663-3785-460a-9b15-9cf81c0ba9e7"}}},"nbformat":4,"nbformat_minor":5}